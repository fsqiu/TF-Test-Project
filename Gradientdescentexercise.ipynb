{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb #pip install import_ipynb, used to import other ipy modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2* np.random.rand(100,1)\n",
    "y = 4+3*X+np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import LinearRegressionModelIPY #commented out because it is not necessary in order to get the variables over\n",
    "eta = .1 #learning rate\n",
    "n_iterations = 1000\n",
    "m = 100 #number of samples\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "X_b = np.c_[np.ones((m,1)),X]\n",
    "for iteration in range (n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    #negative to this batch gradient descent is that it requires the entire \n",
    "    #dataset to be placed into memory\n",
    "    #just plugging in the change into partial derivative with relation to theta\n",
    "    #of the cost function(X_b transposed * X_B)\n",
    "    theta = theta - eta*gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1199612 ],\n",
       "       [1.96867085],\n",
       "       [0.97721448],\n",
       "       [0.16999398],\n",
       "       [1.12280567],\n",
       "       [0.26386726],\n",
       "       [1.66154688],\n",
       "       [1.69153062],\n",
       "       [1.69039985],\n",
       "       [1.88308745],\n",
       "       [0.4503373 ],\n",
       "       [1.90359128],\n",
       "       [1.78655053],\n",
       "       [1.29708413],\n",
       "       [0.16962295],\n",
       "       [1.94345192],\n",
       "       [0.58253794],\n",
       "       [1.5768785 ],\n",
       "       [0.02127763],\n",
       "       [0.42157315],\n",
       "       [0.0121783 ],\n",
       "       [0.83315439],\n",
       "       [1.50087693],\n",
       "       [0.93046285],\n",
       "       [1.02190577],\n",
       "       [1.25560822],\n",
       "       [0.08304184],\n",
       "       [0.11686239],\n",
       "       [1.00585855],\n",
       "       [0.82363933],\n",
       "       [1.32416415],\n",
       "       [1.91395166],\n",
       "       [1.76922064],\n",
       "       [0.07811098],\n",
       "       [0.52669279],\n",
       "       [1.67066124],\n",
       "       [1.21014883],\n",
       "       [0.7279153 ],\n",
       "       [1.48945231],\n",
       "       [1.76289415],\n",
       "       [0.17558133],\n",
       "       [0.66232359],\n",
       "       [1.52125464],\n",
       "       [1.70415453],\n",
       "       [1.07645882],\n",
       "       [1.96362966],\n",
       "       [1.65826543],\n",
       "       [1.901698  ],\n",
       "       [0.63177925],\n",
       "       [1.26418107],\n",
       "       [1.91980928],\n",
       "       [0.944581  ],\n",
       "       [1.56082448],\n",
       "       [0.87668622],\n",
       "       [0.76007418],\n",
       "       [1.40075081],\n",
       "       [1.58846069],\n",
       "       [0.86972499],\n",
       "       [0.47985983],\n",
       "       [1.66181983],\n",
       "       [0.21782971],\n",
       "       [0.84050253],\n",
       "       [0.13564517],\n",
       "       [0.9599657 ],\n",
       "       [1.85865893],\n",
       "       [1.9003698 ],\n",
       "       [0.49477655],\n",
       "       [1.37362315],\n",
       "       [1.9048227 ],\n",
       "       [1.61706161],\n",
       "       [1.7521568 ],\n",
       "       [0.32606969],\n",
       "       [1.15368678],\n",
       "       [1.36788775],\n",
       "       [0.17619525],\n",
       "       [1.22655221],\n",
       "       [1.98784231],\n",
       "       [0.78788053],\n",
       "       [0.60344638],\n",
       "       [0.27893267],\n",
       "       [1.04039304],\n",
       "       [0.65293995],\n",
       "       [0.90474031],\n",
       "       [0.33010691],\n",
       "       [1.00490474],\n",
       "       [1.06439685],\n",
       "       [1.98801953],\n",
       "       [0.21187997],\n",
       "       [0.9726469 ],\n",
       "       [0.61189371],\n",
       "       [0.33544974],\n",
       "       [0.97405922],\n",
       "       [0.13325488],\n",
       "       [0.88915905],\n",
       "       [1.33552162],\n",
       "       [0.21565874],\n",
       "       [0.86719519],\n",
       "       [1.81037031],\n",
       "       [0.75395808],\n",
       "       [0.57481629]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic gradient descent\n",
    "n_epochs= 50\n",
    "t0,t1 = 5,50 #hyperparameters\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "theta = np.random.randn(2,1)\n",
    "for epoch in range(n_epochs):#significantly fewer iterations than batch gradient descent\n",
    "    for i in range(m): \n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2*xi.T.dot(xi.dot(theta)-yi) #take the gradient of the two side by side points\n",
    "        eta = learning_schedule(epoch*m+i) #set the learning rate, it gets smaller and smaller in the later epochs \n",
    "        # and smaller later in the same epochlater inside the same epoch\n",
    "        theta = theta - eta * gradients # changes get smaller over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.85670131],\n",
       "       [3.16157766]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
